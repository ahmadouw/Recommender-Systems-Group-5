{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b5ecc5d390fe3fdcc1d7048181fbcbb",
     "grade": false,
     "grade_id": "cell-3a49d0c736ae4826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Project\n",
    "\n",
    "Welcome to the group project! The project is based on the [ACM RecSys 2021 Challenge](https://recsys-twitter.com/).\n",
    "\n",
    "- Detailed information about the task, submission and grading can be found in a [dedicates site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1217340).\n",
    "- Information about the dataset structure [on this site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1218810)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"team_5\" # your team name e.g. 'team_1'\n",
    "team_members = [(\"Simone Andreetto\",\"01635069\"),\n",
    "                (\"Adrian Bracher\",\"\"),\n",
    "                (\"Dominik Mailer\",\"01634043\"),\n",
    "                (\"Andreas Merckel\",\"\"),\n",
    "                (\"Dominik Pülke\",\"12019262\"),\n",
    "                (\"Sebastian Scholz\",\"01526884\"),\n",
    "                (\"Felix Winterleitner\",\"01612776\"),\n",
    "                (\"Ahmadou Wagne\",\"12002293\")] # [(\"Jane Doe\",\"012345678\"), (\"John Doe\",\"012345678\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdcfa030c94d59246d7322f527c9ef7e",
     "grade": true,
     "grade_id": "cell-adf5f6bdd4704e08",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c84ed38479c0195aaa2fa1ce3f7fece",
     "grade": false,
     "grade_id": "cell-07ef37bf8c0d782b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_5\n",
      "[('Simone Andreetto', '01635069'), ('Adrian Bracher', ''), ('Dominik Mailer', '01634043'), ('Andreas Merckel', ''), ('Dominik Pülke', '12019262'), ('Sebastian Scholz', '01526884'), ('Felix Winterleitner', '01612776'), ('Ahmadou Wagne', '12002293')]\n"
     ]
    }
   ],
   "source": [
    "print(team_name)\n",
    "print(team_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../shared/data/project/training/'\n",
    "dataset_type = 'one_hour' # all_sorted, one_day, one_hour, one_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-44158ce35617>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcsv\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mmodel_nn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Recommender-Systems-Group-5/src/model_nn.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;31m# import scikitplot as skplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mimblearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mover_sampling\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mSMOTE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mimblearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpipeline\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mPipeline\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "import model_nn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dataprep import import_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "def parse_input_line(line):\n",
    "    features = line #.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engaging_user_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    tweet_timestamp = features[all_features_to_idx['tweet_timestamp']]\n",
    "    return tweet_id, user_id, input_feats, tweet_timestamp\n",
    "\n",
    "\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                #df = pd.read_csv(f, sep=\"\\x01\")\n",
    "                #print(f\"df: {df}\")\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                for row in linereader:\n",
    "                    tweet_id, user_id, features, tweet_timestamp = parse_input_line(row)   \n",
    "                    reply_pred = reply_pred_model(features) # reply_model\n",
    "                    #retweet_pred = retweet_pred_model(features) # retweet_model\n",
    "                    #quote_pred = quote_pred_model(features) # pred_model\n",
    "                    #fav_pred = fav_pred_model(features) # fav_model\n",
    "                    \n",
    "                    print(features)\n",
    "                    #reply_pred = model_nn.reply_pred_model(features)\n",
    "                    #retweet_pred = model_nn.retweet_pred_model(features)\n",
    "                    #quote_pred = model_nn.quote_pred_model(features)\n",
    "                    #fav_pred = model_nn.fav_pred_model(features)\n",
    "                    \n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    # print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    \n",
    "                    output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "import model_nn\n",
    "import pandas as pd\n",
    "\n",
    "from dataprep import import_data\n",
    "import dataprep\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = [\n",
    "            # \"text_tokens\",\n",
    "            \"hashtags\",\n",
    "            # \"tweet_id\",\n",
    "            \"present_media\",\n",
    "            \"present_links\",\n",
    "            \"present_domains\",\n",
    "            \"tweet_type\",\n",
    "            # \"language\",\n",
    "            # \"tweet_timestamp\",\n",
    "            # \"engaged_with_user_id\",\n",
    "            # \"engaged_with_user_follower_count\",\n",
    "            \"engaged_with_user_following_count\",\n",
    "            \"engaged_with_user_is_verified\",\n",
    "            \"engaged_with_user_account_creation\",\n",
    "            # \"engaging_user_id\",\n",
    "            # \"enaging_user_follower_count\",\n",
    "            # \"enaging_user_following_count\",\n",
    "            # \"enaging_user_is_verified\",\n",
    "            # \"enaging_user_account_creation\",\n",
    "            \"engagee_follows_engager\"\n",
    "    ]\n",
    "\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "def parse_input_line(line):\n",
    "        \n",
    "    features = line #.split(\"\\x01\")\n",
    "    \n",
    "    hashtags = features[all_features_to_idx['hashtags']]\n",
    "    present_media = features[all_features_to_idx['present_media']]\n",
    "    present_links = features[all_features_to_idx['present_links']]\n",
    "    present_domains = features[all_features_to_idx['present_domains']]\n",
    "    tweet_type = features[all_features_to_idx['tweet_type']]\n",
    "    engaged_with_user_following_count = features[all_features_to_idx['engaged_with_user_following_count']]\n",
    "    engaged_with_user_is_verified = features[all_features_to_idx['engaged_with_user_is_verified']]\n",
    "    engaged_with_user_account_creation = features[all_features_to_idx['engaged_with_user_account_creation']]\n",
    "    engagee_follows_engager = features[all_features_to_idx['engagee_follows_engager']]\n",
    "    \n",
    "    return (hashtags, present_media, present_links, present_domains, tweet_type, engaged_with_user_following_count, engaged_with_user_is_verified, engaged_with_user_account_creation, engagee_follows_engager)\n",
    "\n",
    "\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                df = pd.DataFrame(columns=all_features)\n",
    "                i = 0\n",
    "                for row in linereader:\n",
    "                    df.loc[i] = row[:20]\n",
    "                    i += 1\n",
    "                    if i > 10000:\n",
    "                        break\n",
    "                df_complete = df.copy()\n",
    "                df = df.loc[:, used_features]\n",
    "                df = dataprep.transform_data(df)\n",
    "                scale = StandardScaler()\n",
    "                #df = scale.fit_transform(df)\n",
    "                #df = pd.DataFrame(columns=all_features, data=df)\n",
    "                df = pd.DataFrame(scale.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "                for index, row in df.iterrows():\n",
    "                    tweet_id = df_complete.iloc[[index]][\"tweet_id\"]\n",
    "                    user_id = df_complete.iloc[[index]][\"engaging_user_id\"]\n",
    "                    #feature_tuple = parse_input_line(row)   \n",
    "                    #reply_pred = reply_pred_model(features) # reply_model\n",
    "                    #retweet_pred = retweet_pred_model(features) # retweet_model\n",
    "                    #quote_pred = quote_pred_model(features) # pred_model\n",
    "                    #fav_pred = fav_pred_model(features) # fav_model\n",
    "                    \n",
    "                    #print(feature_tuple)\n",
    "                    #print(df.iloc[[index]][\"engaged_with_user_following_count\"])\n",
    "                    reply_pred = model_nn.reply_pred_model(df.iloc[[index]])\n",
    "                    retweet_pred = model_nn.retweet_pred_model(df.iloc[[index]])\n",
    "                    quote_pred = model_nn.quote_pred_model(df.iloc[[index]])\n",
    "                    fav_pred = model_nn.fav_pred_model(df.iloc[[index]])\n",
    "                    \n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    #print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    output.write(f'{tweet_id.values[0]},{user_id.values[0]},{reply_pred[0]},{retweet_pred[0]},{quote_pred[0]},{fav_pred[0]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End NN-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Content Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "import done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_to_data = '../shared/data/project/training/'\n",
    "dataset_type = 'one_hour'\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from dataprep import import_data\n",
    "import dataprep\n",
    "import model_content\n",
    "\n",
    "used_features = model_content.used_features\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "def parse_input_line(line):\n",
    "    features = line #.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engaging_user_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    tweet_timestamp = features[all_features_to_idx['tweet_timestamp']]\n",
    "    return tweet_id, user_id, input_feats, tweet_timestamp\n",
    "\n",
    "\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:])\n",
    "\n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "               linereader = csv.reader(f, delimiter='\\x01')\n",
    "               last_timestamp = None\n",
    "               df = pd.DataFrame(columns=all_features)\n",
    "               i = 0\n",
    "               for row in linereader:\n",
    "                   df.loc[i] = row[:20]\n",
    "                   i += 1\n",
    "\n",
    "               df_complete = df.copy()\n",
    "               df = df.loc[:, used_features]\n",
    "               df = dataprep.transform_data(df)\n",
    "\n",
    "               for index, row in df.iterrows():\n",
    "                   tweet_id = df_complete.iloc[[index]][\"tweet_id\"]\n",
    "                   user_id = df_complete.iloc[[index]][\"engaging_user_id\"]\n",
    "                   reply_pred = model_content.reply_pred_model(df.iloc[[index]])\n",
    "                   retweet_pred = model_content.retweet_pred_model(df.iloc[[index]])\n",
    "                   quote_pred = model_content.quote_pred_model(df.iloc[[index]])\n",
    "                   fav_pred = model_content.fav_pred_model(df.iloc[[index]])\n",
    "                   output.write(f'{tweet_id.values[0]},{user_id.values[0]},{reply_pred[0]},{retweet_pred[0]},{quote_pred[0]},{fav_pred[0]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# END CONTENT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-To-User Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Model class\n",
    "%run -i \"u2u.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models\n",
    "#imported_data = get_imported_data()\n",
    "\n",
    "#u2u_reply = Predictor(\"reply\", imported_data, dump_to_file=True)\n",
    "#u2u_retweet = Predictor(\"retweet\", imported_data, dump_to_file=True)\n",
    "#u2u_quote = Predictor(\"retweet_with_comment\", imported_data, dump_to_file=True)\n",
    "#u2u_fav = Predictor(\"like\", imported_data, dump_to_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from stored files\n",
    "u2u_reply = load(\"model_content/u2u_reply.joblib\")\n",
    "u2u_retweet = load(\"model_content/u2u_retweet.joblib\")\n",
    "u2u_quote = load(\"model_content/u2u_retweet_with_comment.joblib\")\n",
    "u2u_fav = load(\"model_content/u2u_like.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator class that computes the f1 score. Use in evaluate_test_set!\n",
    "class Evaluator:\n",
    "    def __init__(self):\n",
    "        self.tp = 0\n",
    "        self.tn = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        \n",
    "    def add(self, interaction, prediction):\n",
    "        true = 0 if interaction == \"\" else 1\n",
    "        if true == prediction and true == 0:\n",
    "            self.tn += 1\n",
    "        elif true == prediction and true == 1:\n",
    "            self.tp += 1\n",
    "        elif true != prediction and true == 0:\n",
    "            self.fp += 1\n",
    "        elif true != prediction and true == 1:\n",
    "            self.fn += 1\n",
    "            \n",
    "    def get_f1(self):\n",
    "        try:\n",
    "            return self.tp / (self.tp + 0.5 * (self.fn + self.fp))\n",
    "        except:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-To-User Model\n",
    "\n",
    "path_to_data = '../../shared/data/project/validation/'\n",
    "dataset_type = 'one_hour' # all_sorted, one_day, one_hour, one_week\n",
    "\n",
    "\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\", \"retweet\", \"reply\", \"like\", \"retweet_with_comment\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "\n",
    "# adapted to also return the true interaction values\n",
    "def parse_input_line(line):\n",
    "    features = line #.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engaging_user_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    tweet_timestamp = features[all_features_to_idx['tweet_timestamp']]\n",
    "    retweet = features[all_features_to_idx['retweet']]\n",
    "    reply = features[all_features_to_idx['reply']]\n",
    "    like = features[all_features_to_idx['like']]\n",
    "    retweet_with_comment = features[all_features_to_idx['retweet_with_comment']]\n",
    "\n",
    "    return tweet_id, user_id, input_feats, tweet_timestamp, retweet, reply, like, retweet_with_comment\n",
    "\n",
    "\n",
    "#adapted to return the f1 values for each interaction category\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "    \n",
    "    reply_eval = Evaluator()\n",
    "    retweet_eval = Evaluator()\n",
    "    quote_eval = Evaluator()\n",
    "    fav_eval = Evaluator()\n",
    "    \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                for row in linereader:\n",
    "                    tweet_id, user_id, features, tweet_timestamp, retweet, reply, fav, quote = parse_input_line(row)   \n",
    "                    reply_pred = u2u_reply.predict(user_id, tweet_id, binary=True) # reply_model\n",
    "                    retweet_pred = u2u_retweet.predict(user_id, tweet_id, binary=True) # retweet_model\n",
    "                    quote_pred = u2u_quote.predict(user_id, tweet_id, binary=True) # pred_model\n",
    "                    fav_pred = u2u_fav.predict(user_id, tweet_id, binary=True) # fav_model\n",
    "                    \n",
    "                    reply_eval.add(reply, reply_pred)\n",
    "                    retweet_eval.add(retweet, retweet_pred)\n",
    "                    quote_eval.add(quote, quote_pred)\n",
    "                    fav_eval.add(fav, fav_pred)\n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    # print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    \n",
    "                    output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n",
    "        return reply_eval.get_f1(), retweet_eval.get_f1(), quote_eval.get_f1(), fav_eval.get_f1()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reply_eval, retweet_eval, quote_eval, fav_eval = evaluate_test_set()\n",
    "\n",
    "print(f\"F1-Reply: {reply_eval}\")\n",
    "print(f\"F1-Retweet: {reply_tweet}\")\n",
    "print(f\"F1-Quote: {reply_quote}\")\n",
    "print(f\"F1-Like: {reply_fav}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- End User-To-User Model --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = import_data(path_to_data+dataset_type)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" -- unique tweets --\")\n",
    "print(data[\"tweet_id\"].unique().size)\n",
    "print(\" -- engaged users --\")\n",
    "print(data[\"engaged_with_user_id\"].unique().size)\n",
    "print(\" -- engaging users --\")\n",
    "print(data[\"engaging_user_id\"].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf000a0073acaf52bcde389fa20cf1d6",
     "grade": true,
     "grade_id": "cell-d807d29f081e031b",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recsys Challenge Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "  positive = len([x for x in gt if x == 1])\n",
    "  ctr = positive/float(len(gt))\n",
    "  return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "  \n",
    "ground_truth = read_predictions(path_to_data + dataset_type) # will return data in the form (tweet_id, user_id, labed (1 or 0))\n",
    "predictions = read_predictions(\"predictions.csv\") # will return data in the form (tweet_id, user_id, prediction)\n",
    "\n",
    "rce = compute_rce(predictions, ground_truth)\n",
    "average_precision = average_precision_score(ground_truth, predictions)\n",
    "\n",
    "print(rce)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb64051b7be1028772ba5345a94b770206c1b2a0ad40d717997494c8b22a311e"
  },
  "kernelspec": {
   "display_name": "PyCharm (Recommender-Systems-Group-5)",
   "language": "python",
   "name": "pycharm-9908d772"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}