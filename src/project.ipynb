{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "retired-stadium",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b5ecc5d390fe3fdcc1d7048181fbcbb",
     "grade": false,
     "grade_id": "cell-3a49d0c736ae4826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Project\n",
    "\n",
    "Welcome to the group project! The project is based on the [ACM RecSys 2021 Challenge](https://recsys-twitter.com/).\n",
    "\n",
    "- Detailed information about the task, submission and grading can be found in a [dedicates site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1217340).\n",
    "- Information about the dataset structure [on this site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1218810)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "damaged-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"team_5\" # your team name e.g. 'team_1'\n",
    "team_members = [(\"Simone Andreetto\",\"01635069\"),\n",
    "                (\"Adrian Bracher\",\"\"),\n",
    "                (\"Dominik Mailer\",\"01634043\"),\n",
    "                (\"Andreas Merckel\",\"\"),\n",
    "                (\"Dominik Pülke\",\"12019262\"),\n",
    "                (\"Sebastian Scholz\",\"01526884\"),\n",
    "                (\"Felix Winterleitner\",\"01612776\"),\n",
    "                (\"Ahmadou Wagne\",\"12002293\")] # [(\"Jane Doe\",\"012345678\"), (\"John Doe\",\"012345678\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-behavior",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdcfa030c94d59246d7322f527c9ef7e",
     "grade": true,
     "grade_id": "cell-adf5f6bdd4704e08",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recovered-collect",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c84ed38479c0195aaa2fa1ce3f7fece",
     "grade": false,
     "grade_id": "cell-07ef37bf8c0d782b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_5\n",
      "[('Simone Andreetto', '01635069'), ('Adrian Bracher', ''), ('Dominik Mailer', '01634043'), ('Andreas Merckel', ''), ('Dominik Pülke', '12019262'), ('Sebastian Scholz', '01526884'), ('Felix Winterleitner', '01612776'), ('Ahmadou Wagne', '12002293')]\n"
     ]
    }
   ],
   "source": [
    "print(team_name)\n",
    "print(team_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "downtown-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../shared/data/project/training/'\n",
    "dataset_type = 'one_hour' # all_sorted, one_day, one_hour, one_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "from dataprep import import_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-wrist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "def parse_input_line(line):\n",
    "    features = line #.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engaging_user_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    tweet_timestamp = features[all_features_to_idx['tweet_timestamp']]\n",
    "    return tweet_id, user_id, input_feats, tweet_timestamp\n",
    "\n",
    "\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                for row in linereader:\n",
    "                    tweet_id, user_id, features, tweet_timestamp = parse_input_line(row)   \n",
    "                    reply_pred = reply_pred_model(features) # reply_model\n",
    "                    retweet_pred = retweet_pred_model(features) # retweet_model\n",
    "                    quote_pred = quote_pred_model(features) # pred_model\n",
    "                    fav_pred = fav_pred_model(features) # fav_model\n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    # print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    \n",
    "                    output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-spoke",
   "metadata": {},
   "source": [
    "# User-To-User Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complimentary-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Model class\n",
    "%run -i \"u2u.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elegant-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models\n",
    "#imported_data = get_imported_data()\n",
    "\n",
    "#u2u_reply = Predictor(\"reply\", imported_data, dump_to_file=True)\n",
    "#u2u_retweet = Predictor(\"retweet\", imported_data, dump_to_file=True)\n",
    "#u2u_quote = Predictor(\"retweet_with_comment\", imported_data, dump_to_file=True)\n",
    "#u2u_fav = Predictor(\"like\", imported_data, dump_to_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from stored files\n",
    "u2u_reply = load(\"model_content/u2u_reply.joblib\")\n",
    "u2u_retweet = load(\"model_content/u2u_retweet.joblib\")\n",
    "u2u_quote = load(\"model_content/u2u_retweet_with_comment.joblib\")\n",
    "u2u_fav = load(\"model_content/u2u_like.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator class that computes the f1 score. Use in evaluate_test_set!\n",
    "class Evaluator:\n",
    "    def __init__(self):\n",
    "        self.tp = 0\n",
    "        self.tn = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "        \n",
    "    def add(self, interaction, prediction):\n",
    "        true = 0 if interaction == \"\" else 1\n",
    "        if true == prediction and true == 0:\n",
    "            self.tn += 1\n",
    "        elif true == prediction and true == 1:\n",
    "            self.tp += 1\n",
    "        elif true != prediction and true == 0:\n",
    "            self.fp += 1\n",
    "        elif true != prediction and true == 1:\n",
    "            self.fn += 1\n",
    "            \n",
    "    def get_f1(self):\n",
    "        try:\n",
    "            return self.tp / (self.tp + 0.5 * (self.fn + self.fp))\n",
    "        except:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baking-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-To-User Model\n",
    "\n",
    "path_to_data = '../../shared/data/project/validation/'\n",
    "dataset_type = 'one_hour' # all_sorted, one_day, one_hour, one_week\n",
    "\n",
    "\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\", \"retweet\", \"reply\", \"like\", \"retweet_with_comment\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "\n",
    "# adapted to also return the true interaction values\n",
    "def parse_input_line(line):\n",
    "    features = line #.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engaging_user_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    tweet_timestamp = features[all_features_to_idx['tweet_timestamp']]\n",
    "    retweet = features[all_features_to_idx['retweet']]\n",
    "    reply = features[all_features_to_idx['reply']]\n",
    "    like = features[all_features_to_idx['like']]\n",
    "    retweet_with_comment = features[all_features_to_idx['retweet_with_comment']]\n",
    "\n",
    "    return tweet_id, user_id, input_feats, tweet_timestamp, retweet, reply, like, retweet_with_comment\n",
    "\n",
    "\n",
    "#adapted to return the f1 values for each interaction category\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "    \n",
    "    reply_eval = Evaluator()\n",
    "    retweet_eval = Evaluator()\n",
    "    quote_eval = Evaluator()\n",
    "    fav_eval = Evaluator()\n",
    "    \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                for row in linereader:\n",
    "                    tweet_id, user_id, features, tweet_timestamp, retweet, reply, fav, quote = parse_input_line(row)   \n",
    "                    reply_pred = u2u_reply.predict(user_id, tweet_id, binary=True) # reply_model\n",
    "                    retweet_pred = u2u_retweet.predict(user_id, tweet_id, binary=True) # retweet_model\n",
    "                    quote_pred = u2u_quote.predict(user_id, tweet_id, binary=True) # pred_model\n",
    "                    fav_pred = u2u_fav.predict(user_id, tweet_id, binary=True) # fav_model\n",
    "                    \n",
    "                    reply_eval.add(reply, reply_pred)\n",
    "                    retweet_eval.add(retweet, retweet_pred)\n",
    "                    quote_eval.add(quote, quote_pred)\n",
    "                    fav_eval.add(fav, fav_pred)\n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    # print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    \n",
    "                    output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n",
    "        return reply_eval.get_f1(), retweet_eval.get_f1(), quote_eval.get_f1(), fav_eval.get_f1()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "velvet-election",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "reply_eval, retweet_eval, quote_eval, fav_eval = evaluate_test_set()\n",
    "\n",
    "print(f\"F1-Reply: {reply_eval}\")\n",
    "print(f\"F1-Retweet: {reply_tweet}\")\n",
    "print(f\"F1-Quote: {reply_quote}\")\n",
    "print(f\"F1-Like: {reply_fav}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-thread",
   "metadata": {},
   "source": [
    "# -- End User-To-User Model --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = import_data(path_to_data+dataset_type)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" -- unique tweets --\")\n",
    "print(data[\"tweet_id\"].unique().size)\n",
    "print(\" -- engaged users --\")\n",
    "print(data[\"engaged_with_user_id\"].unique().size)\n",
    "print(\" -- engaging users --\")\n",
    "print(data[\"engaging_user_id\"].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-distributor",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf000a0073acaf52bcde389fa20cf1d6",
     "grade": true,
     "grade_id": "cell-d807d29f081e031b",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-wallpaper",
   "metadata": {},
   "source": [
    "# Metrics Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-nelson",
   "metadata": {},
   "source": [
    "## Recsys Challenge Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "  positive = len([x for x in gt if x == 1])\n",
    "  ctr = positive/float(len(gt))\n",
    "  return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "  \n",
    "ground_truth = read_predictions(path_to_data + dataset_type) # will return data in the form (tweet_id, user_id, labed (1 or 0))\n",
    "predictions = read_predictions(\"predictions.csv\") # will return data in the form (tweet_id, user_id, prediction)\n",
    "\n",
    "rce = compute_rce(predictions, ground_truth)\n",
    "average_precision = average_precision_score(ground_truth, predictions)\n",
    "\n",
    "print(rce)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb64051b7be1028772ba5345a94b770206c1b2a0ad40d717997494c8b22a311e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
