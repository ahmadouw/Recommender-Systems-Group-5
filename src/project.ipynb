{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "photographic-tackle",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b5ecc5d390fe3fdcc1d7048181fbcbb",
     "grade": false,
     "grade_id": "cell-3a49d0c736ae4826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Project\n",
    "\n",
    "Welcome to the group project! The project is based on the [ACM RecSys 2021 Challenge](https://recsys-twitter.com/).\n",
    "\n",
    "- Detailed information about the task, submission and grading can be found in a [dedicates site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1217340).\n",
    "- Information about the dataset structure [on this site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1218810)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unsigned-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"team_5\" # your team name e.g. 'team_1'\n",
    "team_members = [(\"Simone Andreetto\",\"01635069\"),\n",
    "                (\"Adrian Bracher\",\"01637180\"),\n",
    "                (\"Dominik Mailer\",\"01634043\"),\n",
    "                (\"Andreas Merckel\",\"00746397\"),\n",
    "                (\"Dominik Pülke\",\"12019262\"),\n",
    "                (\"Sebastian Scholz\",\"01526884\"),\n",
    "                (\"Felix Winterleitner\",\"01612776\"),\n",
    "                (\"Ahmadou Wagne\",\"12002293\")] # [(\"Jane Doe\",\"012345678\"), (\"John Doe\",\"012345678\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-cylinder",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdcfa030c94d59246d7322f527c9ef7e",
     "grade": true,
     "grade_id": "cell-adf5f6bdd4704e08",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aging-exploration",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c84ed38479c0195aaa2fa1ce3f7fece",
     "grade": false,
     "grade_id": "cell-07ef37bf8c0d782b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_5\n",
      "[('Simone Andreetto', '01635069'), ('Adrian Bracher', '01637180'), ('Dominik Mailer', '01634043'), ('Andreas Merckel', '00746397'), ('Dominik Pülke', '12019262'), ('Sebastian Scholz', '01526884'), ('Felix Winterleitner', '01612776'), ('Ahmadou Wagne', '12002293')]\n"
     ]
    }
   ],
   "source": [
    "print(team_name)\n",
    "print(team_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "heavy-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../shared/data/project/validation/'\n",
    "dataset_type = 'one_hour' # all_sorted, one_day, one_hour, one_week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-state",
   "metadata": {},
   "source": [
    "# NN-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expanded-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "import model_nn\n",
    "import pandas as pd\n",
    "\n",
    "from dataprep import import_data\n",
    "import dataprep\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "billion-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = [\n",
    "            # \"text_tokens\",\n",
    "            \"hashtags\",\n",
    "            # \"tweet_id\",\n",
    "            \"present_media\",\n",
    "            \"present_links\",\n",
    "            \"present_domains\",\n",
    "            \"tweet_type\",\n",
    "            # \"language\",\n",
    "            # \"tweet_timestamp\",\n",
    "            # \"engaged_with_user_id\",\n",
    "            # \"engaged_with_user_follower_count\",\n",
    "            \"engaged_with_user_following_count\",\n",
    "            \"engaged_with_user_is_verified\",\n",
    "            \"engaged_with_user_account_creation\",\n",
    "            # \"engaging_user_id\",\n",
    "            # \"enaging_user_follower_count\",\n",
    "            # \"enaging_user_following_count\",\n",
    "            # \"enaging_user_is_verified\",\n",
    "            # \"enaging_user_account_creation\",\n",
    "            \"engagee_follows_engager\"\n",
    "    ]\n",
    "\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "def parse_input_line(line):\n",
    "        \n",
    "    features = line #.split(\"\\x01\")\n",
    "    \n",
    "    hashtags = features[all_features_to_idx['hashtags']]\n",
    "    present_media = features[all_features_to_idx['present_media']]\n",
    "    present_links = features[all_features_to_idx['present_links']]\n",
    "    present_domains = features[all_features_to_idx['present_domains']]\n",
    "    tweet_type = features[all_features_to_idx['tweet_type']]\n",
    "    engaged_with_user_following_count = features[all_features_to_idx['engaged_with_user_following_count']]\n",
    "    engaged_with_user_is_verified = features[all_features_to_idx['engaged_with_user_is_verified']]\n",
    "    engaged_with_user_account_creation = features[all_features_to_idx['engaged_with_user_account_creation']]\n",
    "    engagee_follows_engager = features[all_features_to_idx['engagee_follows_engager']]\n",
    "    \n",
    "    return (hashtags, present_media, present_links, present_domains, tweet_type, engaged_with_user_following_count, engaged_with_user_is_verified, engaged_with_user_account_creation, engagee_follows_engager)\n",
    "\n",
    "\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                df = pd.DataFrame(columns=all_features)\n",
    "                i = 0\n",
    "                for row in linereader:\n",
    "                    df.loc[i] = row[:20]\n",
    "                    i += 1\n",
    "                df_complete = df.copy()\n",
    "                df = df.loc[:, used_features]\n",
    "                df = dataprep.transform_data(df)\n",
    "                scale = StandardScaler()\n",
    "                #df = scale.fit_transform(df)\n",
    "                #df = pd.DataFrame(columns=all_features, data=df)\n",
    "                df = pd.DataFrame(scale.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "                for index, row in df.iterrows():\n",
    "                    tweet_id = df_complete.iloc[[index]][\"tweet_id\"]\n",
    "                    user_id = df_complete.iloc[[index]][\"engaging_user_id\"]\n",
    "                    #feature_tuple = parse_input_line(row)   \n",
    "                    #reply_pred = reply_pred_model(features) # reply_model\n",
    "                    #retweet_pred = retweet_pred_model(features) # retweet_model\n",
    "                    #quote_pred = quote_pred_model(features) # pred_model\n",
    "                    #fav_pred = fav_pred_model(features) # fav_model\n",
    "                    \n",
    "                    #print(feature_tuple)\n",
    "                    #print(df.iloc[[index]][\"engaged_with_user_following_count\"])\n",
    "                    reply_pred = model_nn.reply_pred_model(df.iloc[[index]])\n",
    "                    retweet_pred = model_nn.retweet_pred_model(df.iloc[[index]])\n",
    "                    quote_pred = model_nn.quote_pred_model(df.iloc[[index]])\n",
    "                    fav_pred = model_nn.fav_pred_model(df.iloc[[index]])\n",
    "                    \n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    #print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    output.write(f'{tweet_id.values[0]},{user_id.values[0]},{reply_pred[0]},{retweet_pred[0]},{quote_pred[0]},{fav_pred[0]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "victorian-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-intro",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf000a0073acaf52bcde389fa20cf1d6",
     "grade": true,
     "grade_id": "cell-d807d29f081e031b",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb64051b7be1028772ba5345a94b770206c1b2a0ad40d717997494c8b22a311e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
