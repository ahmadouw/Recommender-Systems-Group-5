{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b5ecc5d390fe3fdcc1d7048181fbcbb",
     "grade": false,
     "grade_id": "cell-3a49d0c736ae4826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Project\n",
    "\n",
    "Welcome to the group project! The project is based on the [ACM RecSys 2021 Challenge](https://recsys-twitter.com/).\n",
    "\n",
    "- Detailed information about the task, submission and grading can be found in a [dedicates site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1217340).\n",
    "- Information about the dataset structure [on this site on TUWEL](https://tuwel.tuwien.ac.at/mod/page/view.php?id=1218810)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"team_5\" # your team name e.g. 'team_1'\n",
    "team_members = [(\"Simone Andreetto\",\"01635069\"),\n",
    "                (\"Adrian Bracher\",\"\"),\n",
    "                (\"Dominik Mailer\",\"01634043\"),\n",
    "                (\"Andreas Merckel\",\"\"),\n",
    "                (\"Dominik Pülke\",\"12019262\"),\n",
    "                (\"Sebastian Scholz\",\"01526884\"),\n",
    "                (\"Felix Winterleitner\",\"01612776\"),\n",
    "                (\"Ahmadou Wagne\",\"12002293\")] # [(\"Jane Doe\",\"012345678\"), (\"John Doe\",\"012345678\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdcfa030c94d59246d7322f527c9ef7e",
     "grade": true,
     "grade_id": "cell-adf5f6bdd4704e08",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c84ed38479c0195aaa2fa1ce3f7fece",
     "grade": false,
     "grade_id": "cell-07ef37bf8c0d782b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_5\n",
      "[('Simone Andreetto', '01635069'), ('Adrian Bracher', ''), ('Dominik Mailer', ''), ('Andreas Merckel', ''), ('Dominik Pülke', '12019262'), ('Sebastian Scholz', ''), ('Felix Winterleitner', '01612776'), ('Ahmadou Wagne', '12002293')]\n"
     ]
    }
   ],
   "source": [
    "print(team_name)\n",
    "print(team_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../shared/data/project/training/'\n",
    "dataset_type = 'one_hour' # all_sorted, one_day, one_hour, one_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "from model import reply_pred_model, retweet_pred_model, quote_pred_model, fav_pred_model \n",
    "from dataprep import import_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare models for U2U-Collaborative filtering\n",
    "%run -i \"u2u.py\"\n",
    "u2u_reply = Predictor(\"reply\", imported_data)\n",
    "u2u_retweet = Predictor(\"retweet\", imported_data)\n",
    "u2u_quote = Predictor(\"retweet_with_comment\", imported_data)\n",
    "u2u_fav = Predictor(\"like\", imported_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        engaging_user_id  like  reply  retweet  \\\n",
      "0       736278C2FEC488516CDA4ED6952A2154     0      0        0   \n",
      "1       19D5367D835484236CAF9DBEF475FF7A     0      0        0   \n",
      "2       40BEB04CF8D3CB02449879668656FFDB     0      0        0   \n",
      "3       6415C94D3C27BA84C069DE049EBB3EDE     0      0        0   \n",
      "4       7E614D5881BC18768880CC374C4BE821     0      0        0   \n",
      "...                                  ...   ...    ...      ...   \n",
      "891742  88A1D59A5ACB3CD87AFBCB58AFB33579     0      0        0   \n",
      "891743  7D704E0ECA4D89F47460049DADEBBD65     0      0        0   \n",
      "891744  58ED1F75F517E65F96C352C42C33E308     0      0        0   \n",
      "891745  1B1C8C719C1BA40D5EE7DF756ACDF0AD     0      0        0   \n",
      "891746  50E428669DE88261429DE5A10FED3DDE     0      0        0   \n",
      "\n",
      "        retweet_with_comment                          tweet_id  \n",
      "0                          1  395A05A1E8A0A4CEB2E623281C7A41EE  \n",
      "1                          0  81E8247F4E74A0FCDBA911E1A3CB5412  \n",
      "2                          0  81E8247F4E74A0FCDBA911E1A3CB5412  \n",
      "3                          0  81E8247F4E74A0FCDBA911E1A3CB5412  \n",
      "4                          0  81E8247F4E74A0FCDBA911E1A3CB5412  \n",
      "...                      ...                               ...  \n",
      "891742                     0  FDD2D7997110248166FB05C2E8609696  \n",
      "891743                     0  BB1139C86AAB39557087F9B8BEA3D6A3  \n",
      "891744                     0  D03C8A65EA0A1197483C9D9051F49BD4  \n",
      "891745                     0  24166BF0D0D45F2D811606E3417AE975  \n",
      "891746                     0  08F2118E055A9D8DE1C26E886A7D84F3  \n",
      "\n",
      "[891747 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(imported_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "def parse_input_line(line):\n",
    "    features = line #.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engaging_user_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    tweet_timestamp = features[all_features_to_idx['tweet_timestamp']]\n",
    "    return tweet_id, user_id, input_feats, tweet_timestamp\n",
    "\n",
    "\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                for row in linereader:\n",
    "                    tweet_id, user_id, features, tweet_timestamp = parse_input_line(row)   \n",
    "                    reply_pred = reply_pred_model(features) # reply_model\n",
    "                    retweet_pred = retweet_pred_model(features) # retweet_model\n",
    "                    quote_pred = quote_pred_model(features) # pred_model\n",
    "                    fav_pred = fav_pred_model(features) # fav_model\n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    # print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    \n",
    "                    output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\\\n",
    "                \"tweet_type\",\"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\\\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\\\n",
    "               \"engaging_user_id\", \"enaging_user_follower_count\", \"enaging_user_following_count\", \"enaging_user_is_verified\",\\\n",
    "               \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
    "\n",
    "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
    "\n",
    "def parse_input_line(line):\n",
    "    features = line #.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engaging_user_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    tweet_timestamp = features[all_features_to_idx['tweet_timestamp']]\n",
    "    return tweet_id, user_id, input_feats, tweet_timestamp\n",
    "\n",
    "\n",
    "def evaluate_test_set():\n",
    "    expanded_path = os.path.expanduser(path_to_data)\n",
    "    part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "    part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "        \n",
    "    with open('results.csv', 'w') as output:\n",
    "        for file in part_files:\n",
    "            with open(file, 'r') as f:\n",
    "                linereader = csv.reader(f, delimiter='\\x01')\n",
    "                last_timestamp = None\n",
    "                for row in linereader:\n",
    "                    tweet_id, user_id, features, tweet_timestamp = parse_input_line(row)   \n",
    "                    reply_pred = u2u_reply.predict(user_id, tweet_id) # reply_model\n",
    "                    retweet_pred = u2u_retweet.predict(user_id, tweet_id) # retweet_model\n",
    "                    quote_pred = u2u_quote.predict(user_id, tweet_id) # pred_model\n",
    "                    fav_pred = u2u_fav.predict(user_id, tweet_id) # fav_model\n",
    "                    \n",
    "                    # print(str(tweet_timestamp))\n",
    "                    # print(str(reply_pred)+\" \"+str(retweet_pred)+\" \"+str(quote_pred)+\" \"+str(fav_pred))\n",
    "                    \n",
    "                    output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../shared/data/project/training/one_hour']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_path = os.path.expanduser(path_to_data)\n",
    "part_files = [os.path.join(expanded_path, f) for f in os.listdir(expanded_path) if dataset_type in f]\n",
    "part_files = sorted(part_files, key = lambda x:x[-5:]) \n",
    "part_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = import_data(path_to_data+dataset_type)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" -- unique tweets --\")\n",
    "print(data[\"tweet_id\"].unique().size)\n",
    "print(\" -- engaged users --\")\n",
    "print(data[\"engaged_with_user_id\"].unique().size)\n",
    "print(\" -- engaging users --\")\n",
    "print(data[\"engaging_user_id\"].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf000a0073acaf52bcde389fa20cf1d6",
     "grade": true,
     "grade_id": "cell-d807d29f081e031b",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "  positive = len([x for x in gt if x == 1])\n",
    "  ctr = positive/float(len(gt))\n",
    "  return ctr\n",
    "\n",
    "def compute_rce(pred, gt):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "  \n",
    "ground_truth = read_predictions(path_to_data + dataset_type) # will return data in the form (tweet_id, user_id, labed (1 or 0))\n",
    "predictions = read_predictions(\"predictions.csv\") # will return data in the form (tweet_id, user_id, prediction)\n",
    "\n",
    "rce = compute_rce(predictions, ground_truth)\n",
    "average_precision = average_precision_score(ground_truth, predictions)\n",
    "\n",
    "print(rce)\n",
    "print(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to edit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb64051b7be1028772ba5345a94b770206c1b2a0ad40d717997494c8b22a311e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
